{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UVt3EHsJhvj1tgM_dmObKM2cnhhOGCcY",
      "authorship_tag": "ABX9TyPI6lEyOK1I4DVCvlrs0meY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shireesh-kumar/RVS-UNet/blob/main/TEST_RetinalVesselSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing required libraries"
      ],
      "metadata": {
        "id": "iyhBBUBa8jM2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_heOg4_jEU7D"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "import os, time\n",
        "from operator import add\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "import torch.nn as nn\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code taken from Training file"
      ],
      "metadata": {
        "id": "k9joTr9fGWHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self, in_c, out_c):\n",
        "      super().__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
        "      self.bn1 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "      self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
        "      self.bn2 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "      x = self.conv1(inputs)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.relu(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "class encoder_block(nn.Module):\n",
        "  def __init__(self, in_c, out_c):\n",
        "      super().__init__()\n",
        "\n",
        "      self.conv = conv_block(in_c, out_c)\n",
        "      self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "      x = self.conv(inputs)\n",
        "      p = self.pool(x)\n",
        "\n",
        "      return x, p\n",
        "\n",
        "class decoder_block(nn.Module):\n",
        "  def __init__(self, in_c, out_c):\n",
        "      super().__init__()\n",
        "\n",
        "      self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "      self.conv = conv_block(out_c+out_c, out_c)\n",
        "\n",
        "  def forward(self, inputs, skip):\n",
        "      x = self.up(inputs)\n",
        "      x = torch.cat([x, skip], axis=1)\n",
        "      x = self.conv(x)\n",
        "      return x\n",
        "\n",
        "class build_unet(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      \"\"\" Encoder \"\"\"\n",
        "      self.e1 = encoder_block(3, 64)\n",
        "      self.e2 = encoder_block(64, 128)\n",
        "      self.e3 = encoder_block(128, 256)\n",
        "      self.e4 = encoder_block(256, 512)\n",
        "\n",
        "      \"\"\" Bottleneck \"\"\"\n",
        "      self.b = conv_block(512, 1024)\n",
        "\n",
        "      \"\"\" Decoder \"\"\"\n",
        "      self.d1 = decoder_block(1024, 512)\n",
        "      self.d2 = decoder_block(512, 256)\n",
        "      self.d3 = decoder_block(256, 128)\n",
        "      self.d4 = decoder_block(128, 64)\n",
        "\n",
        "      \"\"\" Classifier \"\"\"\n",
        "      self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "      \"\"\" Encoder \"\"\"\n",
        "      s1, p1 = self.e1(inputs)\n",
        "      s2, p2 = self.e2(p1)\n",
        "      s3, p3 = self.e3(p2)\n",
        "      s4, p4 = self.e4(p3)\n",
        "\n",
        "      \"\"\" Bottleneck \"\"\"\n",
        "      b = self.b(p4)\n",
        "\n",
        "      \"\"\" Decoder \"\"\"\n",
        "      d1 = self.d1(b, s4)\n",
        "      d2 = self.d2(d1, s3)\n",
        "      d3 = self.d3(d2, s2)\n",
        "      d4 = self.d4(d3, s1)\n",
        "\n",
        "      outputs = self.outputs(d4)\n",
        "\n",
        "      return outputs\n",
        "\n",
        "# #Checking the output of the model\n",
        "# x = torch.randn((2, 3, 512, 512))\n",
        "# f = build_unet()\n",
        "# y = f(x)\n",
        "# print(y.shape)"
      ],
      "metadata": {
        "id": "dUk7J23mF07g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utility Functions\n",
        "def seeding(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "sQmHwcmDGLUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "nFt1VIKsG4MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\" Ground truth \"\"\"\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_true = y_true > 0.5\n",
        "    y_true = y_true.astype(np.uint8)\n",
        "    y_true = y_true.reshape(-1)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.uint8)\n",
        "    y_pred = y_pred.reshape(-1)\n",
        "\n",
        "    score_jaccard = jaccard_score(y_true, y_pred)\n",
        "    score_f1 = f1_score(y_true, y_pred)\n",
        "    score_recall = recall_score(y_true, y_pred)\n",
        "    score_precision = precision_score(y_true, y_pred)\n",
        "    score_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
        "    return mask\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    seeding(42)\n",
        "\n",
        "    \"\"\" Folders \"\"\"\n",
        "    create_dir(\"results\")\n",
        "\n",
        "    \"\"\" Load dataset \"\"\"\n",
        "    test_x = sorted(glob(\"/content/drive/MyDrive/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/test/Original/*.png\"))\n",
        "    test_y = sorted(glob(\"/content/drive/MyDrive/FIVES A Fundus Image Dataset for AI-based Vessel Segmentation/test/Ground truth/*.png\"))\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    H = 256\n",
        "    W = 256\n",
        "    size = (W, H)\n",
        "    checkpoint_path = \"files/checkpoint.pth\"\n",
        "\n",
        "    \"\"\" Load the checkpoint \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = build_unet()\n",
        "    model = model.to(device)\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "    time_taken = []\n",
        "\n",
        "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "        \"\"\" Extract the name \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Reading image \"\"\"\n",
        "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
        "        image = cv2.resize(image, size)\n",
        "        x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
        "        x = x/255.0\n",
        "        x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
        "        x = x.astype(np.float32)\n",
        "        x = torch.from_numpy(x)\n",
        "        x = x.to(device)\n",
        "\n",
        "        \"\"\" Reading mask \"\"\"\n",
        "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "        mask = cv2.resize(mask, size)\n",
        "        y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n",
        "        y = y/255.0\n",
        "        y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n",
        "        y = y.astype(np.float32)\n",
        "        y = torch.from_numpy(y)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
        "            start_time = time.time()\n",
        "            pred_y = model(x)\n",
        "            pred_y = torch.sigmoid(pred_y)\n",
        "            total_time = time.time() - start_time\n",
        "            time_taken.append(total_time)\n",
        "\n",
        "\n",
        "            score = calculate_metrics(y, pred_y)\n",
        "            metrics_score = list(map(add, metrics_score, score))\n",
        "            pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
        "            pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
        "            pred_y = pred_y > 0.5\n",
        "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
        "\n",
        "        \"\"\" Saving masks \"\"\"\n",
        "        ori_mask = mask_parse(mask)\n",
        "        pred_y = mask_parse(pred_y)\n",
        "        line = np.ones((size[1], 10, 3)) * 128\n",
        "\n",
        "        retinal_images = np.concatenate(\n",
        "            [image, line, ori_mask, line, pred_y * 255], axis=1\n",
        "        )\n",
        "        cv2.imwrite(f\"results/{name}.png\", retinal_images)\n",
        "\n",
        "    jaccard = metrics_score[0]/len(test_x)\n",
        "    f1 = metrics_score[1]/len(test_x)\n",
        "    recall = metrics_score[2]/len(test_x)\n",
        "    precision = metrics_score[3]/len(test_x)\n",
        "    acc = metrics_score[4]/len(test_x)\n",
        "    print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}\")\n",
        "\n",
        "    fps = 1/np.mean(time_taken)\n",
        "    print(\"FPS: \", fps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaH0MatfGigu",
        "outputId": "0086501e-acd8-407d-af6e-1291f1b95904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [07:45<00:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard: 0.5653 - F1: 0.7182 - Recall: 0.6712 - Precision: 0.7806 - Acc: 0.9630\n",
            "FPS:  0.5017865851886366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading the results\n",
        "# !zip -r /content/results.zip /content/results"
      ],
      "metadata": {
        "id": "sNofs7xGJFId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzrlL3Ju0OGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}